{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOu2flq1PkixEhaZLyFMQU8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GCsVBB16_Hlf"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["%%capture\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps xformers trl accelerate bitsandbytes"],"metadata":{"id":"SsliH2wDC2eS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","from datasets import load_dataset\n","import torch\n","\n","max_seq_length=2048\n","dtype=None\n","load_in_4bit =True"],"metadata":{"id":"-2x5lex4C3pu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fourbit_models=[\n","    \"unsloth/mistral-7b-v0-bnb-4bit\",\n","    \"unsloth/mistral-7b-listruct-v0.3-bnb-4bit\",\n","    \"unsloth/llama-3-8b-bnb-4bit\",\n","    \"unsloth/llama-3-8b-instruct-bnb-4bit\",\n","    \"unsloth/llama-3-70b-bnb-4bit\",\n","    \"unsloth/phi-3-mini-4k-instruct\",\n","    \"unsloth/minstral-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",\n","    \"unsloth/sloar-10.7b-bnb-4bit\"\n","    ]\n","model,tokenizer=FastLanguageModel.from_pretrained(\n","    model_name=\"unsloth/llama-3-8b-instruct-bnb-4bit\",\n","    max_seq_length=max_seq_length,\n","    dtype=dtype,\n","    load_in_4bit=load_in_4bit\n","     )"],"metadata":{"id":"eYacuemjKfmt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task\n","Write a response that appropriately completes the request in korean language.\n","\n","### Instruction:\n","{}\n","### Input:\n","{}\n","\n","### Response:\n","{}\n","\"\"\"\n","#ë°ì´í„°ë“¤ textë“¤ë¡œ ë³€í™˜\n","EOS_TOKEN =tokenizer.eos_token\n","def formatting_prompt_func(examples):\n","  instructions = examples[\"instruction\"]\n","  inputs=examples[\"input\"]\n","  outputs=examples[\"output\"]\n","  texts=[]\n","  for instructions,inputs,outputs in zip(instructions,inputs,outputs):\n","    text=alpaca_prompt.format(instructions,inputs,outputs)+EOS_TOKEN\n","    texts.append(text)\n","  return {\"text\":texts,}\n","  pass"],"metadata":{"id":"CUs0aA8TKhc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]  # ì§€ì‹œì‚¬í•­ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","    inputs = examples[\"input\"]  # ì…ë ¥ê°’ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","    outputs = examples[\"output\"]  # ì¶œë ¥ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","    texts = []  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n","    for instruction,input,output in zip(instructions, inputs , outputs):\n","        # EOS_TOKENì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ìƒì„±ì´ ë¬´í•œíˆ ì§„í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","        text = alpaca_prompt.format(instruction,input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return {\n","        \"text\": texts,  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n","    }\n","\n","#ì‚¬ìš©í•  csvë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì½”ë“œ\n","df = pd.read_csv('/content/drive/MyDrive/sample/law_usloth_data.csv')\n","\n","# Convert the DataFrame to a Hugging Face dataset\n","dataset = Dataset.from_pandas(df)\n","\n","# ë°ì´í„°ì…‹ì— formatting_prompts_func í•¨ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.\n","dataset = dataset.map(\n","    formatting_prompts_func,\n","    batched=True,\n",")"],"metadata":{"id":"0MTi_5JhKi0Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","\n","# ğŸ’¡ ëª¨ë¸ì„ ë¡œë“œí•´ì„œ ì‚¬ìš©í•  ì¤€ë¹„í•˜ëŠ” ì½”ë“œì—ìš”\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=16,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n","    lora_alpha=16,\n","    lora_dropout=0,  # âœ… ì˜¤íƒ€ ìˆ˜ì •ë¨\n","    bias=\"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state=3407,\n","    use_rslora=False,\n","    loftq_config=None\n",")"],"metadata":{"id":"XGFUbX5JKkUM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"WANDB_DISABLED\"]=\"True\"\n","\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","#ì‹¤ì œë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=dataset,\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=TrainingArguments(\n","        per_device_train_batch_size = 8,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 100,\n","        max_steps = 200,#ì´ê²Œ ì—í¬í¬ì—ìš”\n","        learning_rate = 2e-4,\n","        lr_scheduler_type = \"cosine\",\n","        weight_decay = 0.01,\n","        fp16 = False,\n","        bf16 = True,\n","        logging_steps = 10,\n","        save_steps = 200,\n","        save_total_limit = 2,\n","        seed = 42,\n","        optim = \"adamw_8bit\",\n","        output_dir = \"output\",\n","        report_to = \"none\"\n","    )\n",")\n","trainer_state=trainer.train()"],"metadata":{"id":"zAZiU9vbKmVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ì¶”ë¡ ìš©ìœ¼ë¡œ ë³€í™˜\n","model = FastLanguageModel.for_inference(model)\n","\n","# --- ë²•ë¥  QA Prompt í…œí”Œë¦¿ ---\n","def law_prompt(instruction, question, context=\"\"):\n","    return f\"\"\"### instruction:\n","{instruction}\n","\n","### question:\n","{question}\n","\n","### ë‹µë³€:\n","\"\"\"\n","\n","# ì…ë ¥ë°ì´í„°ì—ìš”\n","instruction = \"ë²•ë¥  ì§ˆì˜ì‘ë‹µì„ ì‘ì„±í•  ë•Œ, ë²• ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•  ê²ƒ\"\n","question = \"ì–´ë–¤ ì°½ì‘ë¬¼ì€ ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ë°›ì„ ìˆ˜ ì—†ë‹¤ê³  í•˜ëŠ”ë°, ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n","\n","prompt = law_prompt(instruction, question)\n","\n","#ë°›ì€ ì…ë ¥ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì´ ì¶œë ¥ì„ ë§Œë“¤ì–´ë‚´ê²Œ í•˜ëŠ” ì½”ë“œì—ìš”\n","inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n","outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n","\n","# ê²°ê³¼ ì¶œë ¥\n","answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","print(\"=== ê²°ê³¼ ===\")\n","print(answer.split(\"### ë‹µë³€:\")[-1].strip())"],"metadata":{"id":"tOIx25dDKodD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ì…ë ¥ë°ì´í„°ì—ìš”\n","instruction = \"ë²•ë¥  ì§ˆì˜ì‘ë‹µì„ ì‘ì„±í•  ë•Œ, ë²• ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•  ê²ƒ\"\n","question = \"ë‚´ê°€ ë§Œì•½ ë¼ì´ì„¼ìŠ¤ê°€ ë“±ë¡ëœ ì œí’ˆì„ ë¬´ë‹¨ìœ¼ë¡œ ì‚¬ìš©í•˜ì˜€ì„ë•Œ ì–´ë–»ê²Œë˜?\"\n","\n","prompt = law_prompt(instruction, question)\n","\n","# Tokenize & Generate\n","inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n","outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)\n","\n","# ê²°ê³¼ ì¶œë ¥\n","answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","print(\"=== ê²°ê³¼ ===\")\n","print(answer.split(\"### ë‹µë³€:\")[-1].strip())"],"metadata":{"id":"GUSgRQsqKp69"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruction = \"ë²•ë¥  ì§ˆì˜ì‘ë‹µì„ ì‘ì„±í•  ë•Œ, ë²• ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•  ê²ƒ\"\n","question = \"ê·¸ë ‡ë‹¤ë©´ ì–¸ì œ í˜•ì‚¬ìƒìœ¼ë¡œë„ ì²˜ë²Œë°›ì„ ìˆ˜ ìˆìœ¼ë©°, ë²•ì  ì¡°ì¹˜ê°€ ë‚´ë ¤ì§ˆ ìˆ˜ ìˆì–´?\"\n","\n","prompt = law_prompt(instruction, question)\n","\n","# Tokenize & Generate\n","inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n","outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)\n","\n","# ê²°ê³¼ ì¶œë ¥\n","answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]"],"metadata":{"id":"eTdRFCZHKrKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== ê²°ê³¼ ===\")\n","print(answer.split(\"### ë‹µë³€:\")[-1].strip())"],"metadata":{"id":"Dky8kzOIKslM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ì—¬ê¸°ì„œ ë¶€í„°ëŠ” í—ˆê¹…í˜ì´ìŠ¤ì˜ ë“¤ì–´ê°€ì„œ ëª¨ë¸ ì—…ë¡œë“œ í•˜ëŠ” ì½”ë“œì¸ë° ì•„ì§ ë§Œì¡±ìŠ¤ëŸ½ì§€ê°€ ì•Šì•„ì„œ ì•ˆí•˜ê³  ìˆì–´ìš”\n","from huggingface_hub import login\n","\n","# 1. í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸\n","huggingface_token = \"githubì—ì„œ í† ê·¼ì€ ê°€ë¦¬ë¼ê³  í•˜ë„¤ìš”\"\n","huggingface_repo = \"kim0924/Llama-3-law-8b-version3-merged\"\n","login(token=huggingface_token)\n","\n","# 2. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ push_to_hub\n","model.push_to_hub(\n","    huggingface_repo,\n","    use_temp_dir=False,\n","    private=True,  # ê³µê°œ ì—¬ë¶€ ì„ íƒ\n",")\n","\n","tokenizer.push_to_hub(\n","    huggingface_repo,\n","    use_temp_dir=False,\n",")"],"metadata":{"id":"jFRNQKM6Kt_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import create_repo\n","\n","create_repo(\n","    repo_id=\"kim0924/Llama-3-law-8b-version2-gguf\",\n","    token=\"githubì—ì„œ í† ê·¼ì€ ê°€ë¦¬ë¼ê³  í•˜ë„¤ìš”\",\n","    repo_type=\"model\",  # ë°˜ë“œì‹œ 'model'ë¡œ ì§€ì •\n","    exist_ok=True       # ì´ë¯¸ ìˆì–´ë„ ì—ëŸ¬ ì—†ì´ ë„˜ì–´ê°\n",")\n"],"metadata":{"id":"7aye79I2KvFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["huggingface_token=\"githubì—ì„œ í† ê·¼ì€ ê°€ë¦¬ë¼ê³  í•˜ë„¤ìš” \"\n","huggingface_repo=\"kim0924/Llama-3-law-8b-version3-gguf\"\n","save_method=(\"merged_16bit\")\n","qantization_method=\"q8_0\""],"metadata":{"id":"pD5OSHY5KwBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.push_to_hub_gguf(\n","    huggingface_repo,\n","    tokenizer,\n","    token=huggingface_token,\n","    quantization_method=qantization_method\n",")"],"metadata":{"id":"bsJJNTlbKyfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from datasets import Dataset\n","\n","fileName = \"indata_kor\"\n","dataset_Path = \"/content/drive/MyDrive/sample\"\n","csv_file_path = os.path.join(dataset_Path, f\"{fileName}.csv\")\n","\n","df = pd.read_csv(csv_file_path, encoding=\"utf-8\")\n","dataset = Dataset.from_pandas(df)\n","\n","df = df[['instruction', 'output']]\n","df[\"input\"]=\"\"\n","dataset = Dataset.from_pandas(df)\n","\n","from huggingface_hub import login\n","token_key = \"í† í° ê°€ë¦¬ê¸°\"\n","state=login(token=token_key)\n","\n","dataset.push_to_hub(\"kim0924/lama3_kim_unslot_data\")"],"metadata":{"id":"fZGQPDRXK0ov"},"execution_count":null,"outputs":[]}]}